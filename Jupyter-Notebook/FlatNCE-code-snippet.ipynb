{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4781e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from typing import Dict, List, Tuple, Optional, Set\n",
    "import torch\n",
    "from torch import nn  \n",
    "from torch.utils import data  \n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2112855e",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = torch.nn.Softmax(dim=1)\n",
    "crossentropy = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def LossFlatNCE(feat1, feat2, inv_temp=1., feat2_transposed=False, normalizer=None):\n",
    "    \n",
    "    '''\n",
    "    feat1   bs1 x dim\n",
    "    feat2   bs2 x dim (dim x bs2 if feat2_tranposed is True)\n",
    "    normalizer(x, dim=1)\n",
    "    \n",
    "    Official implementation of\n",
    "    Junya Chen, et al. Simpler, Faster, Stronger: Breaking The log-K Curse On Contrastive Learners With FlatNCE\n",
    "    NeurIPS 2021 SSL Workshop\n",
    "    https://arxiv.org/abs/2107.01152\n",
    "    Some of the results are published in NeurIPS 2022 paper \n",
    "    Tight Mutual Information Estimation With Contrastive Fenchel-Legendre Optimization\n",
    "    \n",
    "    bs1<=bs2, and (input1[i], input2[i]) are positive pairs\n",
    "    all (input1[i], input2[j]) i!=j are negative pairs\n",
    "    when bs1<bs2, the negative samples are augmented (e.g., momentum contrastive (MoCo))\n",
    "    '''\n",
    "    \n",
    "    assert len(feat1.size())==2, 'input1 dimension should be batch_size x feature_dim'\n",
    "    assert len(feat2.size())==2, 'input2 dimension should be batch_size x feature_dim (or transpose)'\n",
    "    \n",
    "    if feat2_transposed is False:\n",
    "        feat2 = feat2.t()\n",
    "        \n",
    "    assert feat1.size(dim=1)==feat2.size(dim=0), 'The feature dimension should match for input1 and input2'\n",
    "    \n",
    "    n1 = feat1.size(dim=0)\n",
    "    n2 = feat2.size(dim=1)\n",
    "    assert n1<=n2, 'Size of input2 should not be less than input1'\n",
    "    \n",
    "    # Normlize feature if normalizer is specified\n",
    "    if normalizer is not None:\n",
    "        feat1 = normalizer(feat1, dim=1)\n",
    "        feat2 = normalizer(feat2, dim=0)\n",
    "    \n",
    "    similarity = feat1 @ feat2\n",
    "    \n",
    "    mask = torch.eye(n1, dtype=torch.bool)\n",
    "    if n1<n2:\n",
    "        mask = torch.cat([mask,torch.zeros([n1,n2-n1], dtype=torch.bool)], dim=1)\n",
    "    \n",
    "    positives = similarity[mask].view(n1,-1)\n",
    "    negatives = similarity[~mask].view(n1,-1)\n",
    "    \n",
    "    contrastive_logits = inv_temp * (negatives - positives)\n",
    "    \n",
    "    s = torch.logsumexp(contrastive_logits, dim=1)\n",
    "    \n",
    "    loss_vec = torch.exp(s-s.detach())\n",
    "    \n",
    "    loss = loss_vec.mean()-1.\n",
    "    \n",
    "    logits = contrastive_logits\n",
    "    weight = softmax(logits)\n",
    "    ness_vec = (1./(torch.square(weight).sum(dim=1)))/logits.size(dim=1) # [1/size, 1]\n",
    "    ness = ness_vec.mean()\n",
    "    \n",
    "    res = dict()\n",
    "    res['loss_vec'] = loss_vec\n",
    "    res['similarity'] = similarity\n",
    "    res['contrastive_logits'] = contrastive_logits\n",
    "    res['ness_vec'] = ness_vec\n",
    "    res['ness'] = ness\n",
    "    \n",
    "    labels = torch.arange(start=0,end=similarity.size(0),dtype=torch.long).to(loss.device) \n",
    "    res['mi'] = -crossentropy(inv_temp * similarity, labels).mean() + torch.log(torch.Tensor([similarity.size(1)]))\n",
    "    \n",
    "    return loss, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c914ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_normalizer(x, dim=1):\n",
    "    \n",
    "    norm = torch.sqrt(torch.square(x).sum(dim=dim,keepdim=True))\n",
    "    x_norm = x / norm\n",
    "    \n",
    "    return x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e7d689ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs1 = 10\n",
    "bs2 = 15\n",
    "dim = 20\n",
    "\n",
    "x1 = torch.Tensor(np.random.randn(bs1,dim))\n",
    "x2 = torch.Tensor(np.random.randn(bs2,dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e377d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatnce, res = LossFlatNCE(x1,x2,normalizer=l2_normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2fdd2f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0728])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['mi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbdc55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res['ness'] # Normalized Effective Sample-Size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cytao",
   "language": "python",
   "name": "cytao"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
